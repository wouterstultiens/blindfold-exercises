# UX Research Corpus (BlindfoldExercises)

## Source Index

| ID | Source | Why trusted | Key finding | App implication | Confidence |
|---|---|---|---|---|---|
| S01 | W3C WCAG 2.2 (Rec): https://www.w3.org/TR/WCAG22/ | W3C Recommendation | Accessibility requirements are baseline quality constraints, not optional polish. | Treat accessibility as core product quality gate for all flows. | High |
| S02 | WCAG 2.2 Understanding 2.5.8 Target Size (Minimum): https://www.w3.org/WAI/WCAG22/Understanding/target-size-minimum.html | W3C support guidance | Minimum 24x24 CSS px target size (with exceptions). | Keep all interactive controls at or above this minimum; primary actions larger. | High |
| S03 | Apple Design Tips (touch target 44x44 pt): https://developer.apple.com/design/tips/ | Official platform guidance | Mobile controls should support reliable touch with generous targets. | Set iOS-friendly tap targets >=44 pt for key controls in focused mode. | High |
| S04 | Android accessible app guidance (touch targets): https://developer.android.com/training/accessibility/accessible-app.html | Official platform guidance | Android recommends sufficiently large touch targets (commonly 48dp guidance). | Set Android baseline targets >=48dp for primary action areas. | High |
| S05 | web.dev Accessible tap targets: https://web.dev/articles/accessible-tap-targets | Google developer guidance | 48x48 CSS px target with spacing reduces accidental taps. | Use 48px primary action height and 8px+ spacing in mobile training actions. | High |
| S06 | W3C Mobile Accessibility: https://www.w3.org/WAI/standards-guidelines/mobile/ | W3C program guidance | Mobile accessibility has specific interaction and viewport constraints. | Design and test all critical flows on small touch viewports by default. | High |
| S07 | WAI-ARIA APG keyboard interface: https://www.w3.org/WAI/ARIA/apg/practices/keyboard-interface/ | W3C APG | Predictable keyboard focus/order semantics are required for usable keyboard navigation. | Define keyboard-first behavior for tabs, select controls, and grading buttons. | High |
| S08 | MDN prefers-reduced-motion: https://developer.mozilla.org/docs/Web/CSS/%40media/prefers-reduced-motion | Standard-aligned developer reference | Motion should adapt for users who request reduced motion. | Keep transitions subtle and disable non-essential animation under reduced-motion. | High |
| S09 | NN/g Ten Usability Heuristics: https://www.nngroup.com/articles/ten-usability-heuristics/ | Established UX research org | Visibility of system status, consistency, error prevention, and user control are core UX quality drivers. | Make run state, reveal state, and sync/deletion status always explicit and reversible where possible. | High |
| S10 | NN/g Progressive Disclosure: https://www.nngroup.com/articles/progressive-disclosure/ | Established UX research org | Hide advanced complexity until needed to reduce cognitive load. | Keep training setup minimal; show deeper settings only when relevant. | High |
| S11 | NN/g response-time limits: https://www.nngroup.com/articles/response-times-3-important-limits/ | Classic UX latency benchmark | ~0.1s feels instant, ~1s keeps flow, ~10s requires strong feedback. | Prioritize instant feedback for answer submission; show clear loading states when puzzle fetch is slower. | High |
| S12 | NN/g Mobile Navigation Patterns: https://www.nngroup.com/articles/mobile-navigation-patterns/ | Observational UX evidence | Mobile nav success depends on low-effort reach and clear information hierarchy. | Keep top-level IA shallow with unambiguous Training/Progress separation. | Medium |
| S13 | web.dev LCP: https://web.dev/articles/lcp | Core Web Vitals guidance | Fast content render affects perceived and measured quality. | Optimize first meaningful training view to load quickly on mobile networks. | High |
| S14 | web.dev INP: https://web.dev/inp/ | Core Web Vitals guidance | Input responsiveness is critical for interaction quality. | Minimize interaction delay after taps on reveal/grade/start controls. | High |
| S15 | web.dev RAIL model: https://web.dev/rail/ | Google performance model | UX quality is tied to response/animation/load/idle budgets. | Use performance budgets for app startup, tap response, and animation smoothness. | High |
| S16 | Roediger & Karpicke (2006): https://pubmed.ncbi.nlm.nih.gov/16507066/ | Peer-reviewed memory research | Retrieval practice improves long-term retention more than repeated study. | Keep recall-first loop central: prompt -> recall -> reveal -> self-grade. | High |
| S17 | Cepeda et al. (2006): https://pubmed.ncbi.nlm.nih.gov/16719566/ | Meta-analysis | Distributed practice yields better retention than massed practice. | Promote short frequent sessions and streak continuity over marathon-only sessions. | High |
| S18 | Karpicke & Blunt (2011): https://pubmed.ncbi.nlm.nih.gov/21252317/ | Peer-reviewed experimental research | Retrieval practice can outperform elaborative study methods for meaningful learning. | Prioritize active recall UX above passive review UX in puzzle flow. | High |
| S19 | Dunlosky et al. (2013): https://journals.sagepub.com/doi/10.1177/1529100612453266 | Review of learning techniques | Practice testing and distributed practice are among highest-utility techniques. | Make progress views reinforce repeated testing cadence and schedule consistency. | High |
| S20 | Chase & Simon (1973): https://www.sciencedirect.com/science/article/abs/pii/0010028573900042 | Foundational chess cognition study | Chess expertise relies on pattern/chunk recognition in meaningful positions. | Keep puzzle content structurally meaningful and avoid arbitrary/noisy stimuli. | High |
| S21 | Saariluoma & Kalakoski (1998): https://pubmed.ncbi.nlm.nih.gov/9640433/ | Peer-reviewed chess imagery study | Blindfold skill strongly depends on domain knowledge quality, not generic memory only. | Position blindfold training as pattern-anchored visualization, not raw memorization drills. | Medium |
| S22 | Gobet & Campitelli (2007): https://pubmed.ncbi.nlm.nih.gov/17201516/ | Peer-reviewed expertise study | Deliberate practice matters but does not explain all variance; constraints and individual differences remain. | Design adaptive difficulty and avoid one-size-fits-all expectations in progress feedback. | Medium |
| S23 | Self-Determination Theory (Ryan & Deci, 2000): https://pubmed.ncbi.nlm.nih.gov/11392867/ | Foundational motivation theory | Autonomy, competence, relatedness drive sustained intrinsic motivation. | Emphasize user control and competence feedback; avoid manipulative gamification noise. | High |
| S24 | Chess.com Vision trainer help: https://support.chess.com/en/articles/8615408-what-is-vision | Official product documentation | Users value focused board-vision tasks with adjustable challenge types. | Keep drill framing explicit and configurable without overcomplication. | Medium |
| S25 | Lichess puzzle themes: https://lichess.org/training/themes | Official product taxonomy | Rich tactical categorization helps users train intentfully. | Future drill expansion should support meaningful categories and tags in progress filters. | Medium |
| S26 | Chessable MoveTrainer review intervals: https://support.chess.com/en/articles/10319267-when-will-the-variations-be-ready-for-my-review | Official product/support guidance | Spaced review scheduling is explicit and trusted by serious learners. | Add future-ready hooks for review cadence indicators in progress UX. | Medium |
| S27 | Listudy Blind Tactics feature: https://listudy.org/en/features/blind-tactics | Official product feature page | Frozen-board blind tactics creates strong visualization pressure with simple UI. | Keep focused mode interface minimal and distraction-free during recall. | Medium |
| S28 | ChessTempo opening trainer: https://chesstempo.com/opening-training/repertoire | Official product page | Feedback + spaced recall in a focused training workflow supports retention. | Keep post-attempt feedback immediate and linked to longitudinal progress. | Medium |
| S29 | Aimchess product overview: https://aimchess.com/ | Official product messaging | Personalized insights and clear progress narratives are strong user-value signals. | Progress tab should answer "what improved, what to train next" with minimal friction. | Low |

## Synthesis Notes
- Highest-confidence design rules come from S01-S08 and S16-S19.
- Chess-domain personalization and benchmark patterns are directional (S24-S29), used as secondary evidence.
- Where benchmark products conflict with standards, standards win.

## Known Gaps
- Limited public RCT-level evidence specific to blindfold chess UI patterns.
- Strong direct evidence for session-length UX in chess apps is sparse; apply learning-science transfer carefully.
